## AI&LMM安全隐私 

agentic_security  大型语言模型 (LLM) 的开源漏洞扫描程序，保护人工智能系统免受越狱、模糊测试和多模式攻击。 https://github.com/msoedov/agentic_security

Awesome-LM-SSP  大模型安全隐私集 https://github.com/ThuCCSLab/Awesome-LM-SSP

agentic-radar 大模型代理端工作流安全扫描 https://github.com/splx-ai/agentic-radar

llm-sp 大模型安全和隐私论文和资源集  https://github.com/chawins/llm-sp

llm-security-101 大模型安全安全初步，包括攻防工具及其现状  https://github.com/Seezo-io/llm-security-101

AIJack: 机器学习安全和隐私风险模拟器，支持大量攻防算法 https://github.com/Koukyosyumei/AIJack

awesome-ai-security  AI安全框架，标准，学习资源和工具集 https://github.com/ottosulin/awesome-ai-security

PurpleLlama meta的评估和改善大模型安全的工具集  https://github.com/meta-llama/PurpleLlama

llm-security Dropbox的Prompt注入方法 https://github.com/dropbox/llm-security

llm-security 间接Prompt注入，一种模仿大模型进行钓鱼攻击 https://github.com/greshake/llm-security

vulnhuntr 使用大模型和静态分析工具的远程仓库安全评估 https://github.com/protectai/vulnhuntr

Awesome_GPT_Super_Prompting 大模型安全集，包括ChatGPT越狱、GPT 助手提示泄漏、GPTs提示注入、LLM提示安全、超级提示、Prompt 黑客、Prompt安全、AI Prompt工程、对抗性机器学习 、https://github.com/CyberAlbSecOP/Awesome_GPT_Super_Prompting

Awesome-Jailbreak-on-LLMs  大模型越狱集，包括论文、代码、数据集以及评估分析方法 https://github.com/yueliu1999/Awesome-Jailbreak-on-LLMs

LLM Hacker's Handbook  大模型黑客手册 https://github.com/forcesunseen/llm-hackers-handbook

